{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C=4,8,2\n",
    "x=torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow=torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev=x[b,:t+1] #(t,C)\n",
    "        xbow[b,t]=torch.mean(xprev,0)\n",
    "xbow.shape\n",
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8., 7., 6., 5., 4., 3., 2., 1.])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "multmat=torch.triu(torch.ones((T,T)))#\n",
    "print(multmat.sum(1))\n",
    "multmat=(multmat/torch.sum(multmat,0)).T\n",
    "multmat\n",
    "print((multmat@x)[0])\n",
    "print(xbow[0])\n",
    "#(multmat@x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tril(torch.ones((T,T)))\n",
    "#a=a/torch.sum(a,1)\n",
    "torch.sum(a,1,keepdim=True)\n",
    "a=a/torch.sum(a,1,keepdim=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.0894, -0.4926],\n",
      "         [ 0.1490, -0.3199],\n",
      "         [ 0.3504, -0.2238],\n",
      "         [ 0.3525,  0.0545],\n",
      "         [ 0.0688, -0.0396],\n",
      "         [ 0.0927, -0.0682],\n",
      "         [-0.0341,  0.1332]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.8173,  0.4127],\n",
      "         [-0.1342,  0.4395],\n",
      "         [ 0.2711,  0.4774],\n",
      "         [ 0.2421,  0.0694],\n",
      "         [ 0.0084,  0.0020],\n",
      "         [ 0.0712, -0.1128],\n",
      "         [ 0.2527,  0.2149]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 0.1735, -0.0649],\n",
      "         [ 0.1685,  0.3348],\n",
      "         [-0.1621,  0.1765],\n",
      "         [-0.2312, -0.0436],\n",
      "         [-0.1015, -0.2855],\n",
      "         [-0.2593, -0.1630],\n",
      "         [-0.3015, -0.2293]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.4985, -0.5395],\n",
      "         [ 0.4954,  0.3420],\n",
      "         [ 1.0623, -0.1802],\n",
      "         [ 1.1401, -0.4462],\n",
      "         [ 1.0870, -0.4071],\n",
      "         [ 1.0430, -0.1299],\n",
      "         [ 1.1138, -0.1641]]])\n"
     ]
    }
   ],
   "source": [
    "wei=torch.tril(torch.ones((T,T)))\n",
    "wei=wei/torch.sum(wei,1,keepdim=True)\n",
    "xbow2=(wei@x)\n",
    "print(xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril=torch.tril(torch.ones((T,T)))\n",
    "wei=torch.zeros((T,T))\n",
    "wei=wei.masked_fill(tril==0, float('-inf'))\n",
    "wei\n",
    "wei=torch.nn.functional.softmax(wei,1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value vec:  torch.Size([4, 8, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2995, -0.1094, -0.1128,  ..., -0.4096,  0.2465,  0.2027],\n",
       "         [-0.3415,  0.6291,  0.3136,  ..., -0.4373,  0.2854, -0.0337],\n",
       "         [-0.1199,  0.0629,  0.0397,  ..., -0.1505,  0.1627,  0.0887],\n",
       "         ...,\n",
       "         [ 0.0169, -0.1011,  0.1028,  ..., -0.1999,  0.1021,  0.0268],\n",
       "         [ 0.3011,  0.0338, -0.1095,  ...,  1.1276, -0.7868, -0.1009],\n",
       "         [-0.0928,  0.0898, -0.0869,  ..., -0.1779,  0.2235, -0.0851]],\n",
       "\n",
       "        [[ 1.1559,  0.4672,  0.0164,  ...,  0.9784, -1.1849,  0.1425],\n",
       "         [ 0.6249,  0.2133,  0.2003,  ...,  0.6576, -0.7317,  0.0247],\n",
       "         [-0.0698,  0.0612,  0.3269,  ..., -0.0109, -0.0206, -0.5223],\n",
       "         ...,\n",
       "         [ 0.1051, -0.2871,  0.3040,  ...,  0.5272, -0.5171,  0.4236],\n",
       "         [ 0.1604, -0.3717,  0.0207,  ...,  0.7063, -0.6729,  0.4006],\n",
       "         [-0.1056,  0.1657,  0.5304,  ..., -0.0852,  0.0699, -0.5669]],\n",
       "\n",
       "        [[ 0.1406, -0.0884,  0.1732,  ...,  0.3883, -0.5387, -0.2160],\n",
       "         [ 0.0637, -0.4132, -0.0897,  ...,  0.4486, -0.4199, -0.0495],\n",
       "         [-0.2093,  0.3953,  0.4797,  ...,  0.3477, -0.2959, -0.0810],\n",
       "         ...,\n",
       "         [-0.1383,  0.0672,  0.2093,  ...,  0.4374, -0.5312,  0.0078],\n",
       "         [ 0.0648, -0.0987,  0.0917,  ...,  0.2564, -0.3654, -0.2268],\n",
       "         [-0.0281, -0.5585,  0.5921,  ..., -0.0677, -0.1824,  0.4005]],\n",
       "\n",
       "        [[ 0.3386,  0.1548, -0.1693,  ..., -0.7575,  0.2794, -0.0529],\n",
       "         [ 0.4498,  0.0495, -0.1179,  ..., -1.0480,  0.5768,  0.1664],\n",
       "         [ 0.0977,  0.0035, -0.6863,  ...,  0.6304, -0.3720,  0.1264],\n",
       "         ...,\n",
       "         [-0.1188, -0.1884, -0.5330,  ..., -0.1092, -0.4272,  0.0616],\n",
       "         [-0.0899, -0.0923, -0.1622,  ..., -0.1303,  0.0165,  0.2102],\n",
       "         [-0.2123, -0.1449, -0.3203,  ..., -0.2660, -0.1029,  0.0232]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's implement self-attention\n",
    "B,T,C=4,8,32\n",
    "\n",
    "x=torch.randn(B,T,C)\n",
    "\n",
    "\n",
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.Q_linear=torch.nn.Linear(C,C,bias=False)\n",
    "        self.K_linear=torch.nn.Linear(C,C,bias=False)\n",
    "        self.V_linear=torch.nn.Linear(C,C,bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        Q=self.Q_linear(x)  \n",
    "        K=self.K_linear(x)\n",
    "        V=self.V_linear(x)\n",
    "        #for b in range(B):\n",
    "            #print(Q[b]@K[b].T)\n",
    "        wei = torch.nn.functional.softmax(torch.bmm(Q, K.transpose(1, 2)),dim=2)\n",
    "        print('value vec: ', torch.bmm(wei,V).shape)   \n",
    "        return torch.bmm(wei,V)\n",
    "\n",
    "\n",
    "sa=SelfAttention()\n",
    "sa(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0412, -0.0926,  0.0791,  ...,  0.2176,  0.1817, -0.3167],\n",
       "         [-0.0489, -0.0241,  0.1201,  ...,  0.2884,  0.2653, -0.1681],\n",
       "         [-0.0467, -0.0054,  0.1355,  ...,  0.2961,  0.0796, -0.3560],\n",
       "         ...,\n",
       "         [ 0.0204,  0.0401,  0.2390,  ...,  0.1231,  0.2492, -0.3457],\n",
       "         [-0.0357, -0.0333,  0.1248,  ...,  0.1390,  0.2257, -0.2702],\n",
       "         [-0.1059, -0.0265,  0.1538,  ...,  0.2043,  0.0707, -0.2855]],\n",
       "\n",
       "        [[ 0.0239,  0.1958,  0.0060,  ..., -0.0083,  0.2584,  0.0264],\n",
       "         [-0.0884,  0.1171,  0.1170,  ...,  0.0911,  0.1067,  0.1169],\n",
       "         [-0.0454,  0.0857,  0.0811,  ...,  0.1771,  0.0578, -0.0026],\n",
       "         ...,\n",
       "         [-0.0152,  0.1237,  0.1097,  ...,  0.1490,  0.1103,  0.0398],\n",
       "         [-0.0291,  0.1504,  0.0475,  ...,  0.1289,  0.1215,  0.0219],\n",
       "         [-0.0508,  0.0652,  0.1009,  ...,  0.0225,  0.1713,  0.0539]],\n",
       "\n",
       "        [[-0.0954, -0.0644,  0.3255,  ..., -0.0803,  0.3177,  0.0189],\n",
       "         [-0.0906, -0.1257,  0.2720,  ...,  0.0050,  0.1066, -0.0476],\n",
       "         [ 0.3438, -0.0817,  0.4218,  ..., -0.0469,  0.2935, -0.1029],\n",
       "         ...,\n",
       "         [-0.1137, -0.0565,  0.2432,  ..., -0.0743,  0.0876,  0.0270],\n",
       "         [-0.0008,  0.0223,  0.3424,  ..., -0.1145,  0.1578,  0.0783],\n",
       "         [ 0.1171,  0.0293,  0.4105,  ..., -0.0444,  0.0949,  0.0446]],\n",
       "\n",
       "        [[-0.1330, -0.0491, -0.2533,  ..., -0.3463, -0.3667, -0.1207],\n",
       "         [-0.0425, -0.1709, -0.2065,  ..., -0.3650, -0.3282, -0.0842],\n",
       "         [-0.0253, -0.1769, -0.2885,  ..., -0.3394, -0.3411, -0.0909],\n",
       "         ...,\n",
       "         [ 0.0014, -0.1400, -0.3254,  ..., -0.2970, -0.3116, -0.0609],\n",
       "         [-0.1579, -0.0829, -0.3077,  ..., -0.2745, -0.3126, -0.0475],\n",
       "         [-0.0239, -0.1204, -0.1562,  ..., -0.2992, -0.3761, -0.0733]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.H=12\n",
    "        self.d_head=C//self.H\n",
    "        self.QKV_linear=torch.nn.Linear(C,C*3,bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        QKV=self.QKV_linear(x)\n",
    "        Q, K, V = QKV.chunk(3, dim=-1)\n",
    "        Q=Q.view(B,T,self.H,self.d_head).transpose(1,2)\n",
    "        K=K.view(B,T,self.H,self.d_head).transpose(1,2)\n",
    "        V=V.view(B,T,self.H,self.d_head).transpose(1,2)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.d_head ** 0.5)\n",
    "        weights = torch.nn.functional.softmax(scores, dim=-1)  # Shape: [B, H, T, T]\n",
    "\n",
    "        # Weighted sum of values\n",
    "        out = torch.matmul(weights, V)  # Shape: [B, H, T, d_head]\n",
    "\n",
    "        # Concatenate heads and project back to the original dimension\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        print(out.shape)\n",
    "        return out\n",
    "    \n",
    "B,T,C=4,8,768\n",
    "\n",
    "x=torch.randn(B,T,C)\n",
    "ma=MultiHeadAttention()\n",
    "ma(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/andrej-karpathy-experiments/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
